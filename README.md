## Как запустить:
- в главной папке выполнить из терминала команду `./start-all.sh dev` или `./start-all.sh test`
- перейти на https://localhost/services-info-page/ (или для теста еще порт 4014) - это страница с ссылками на сайт, api-документацию и PGAdmin
- или сразу перейти на https://localhost/ - сайт с игрой (или для теста еще порт 4014)
- если в браузере ругнется на сертификат, то нажать Продолжить - проект запускается локально с самоподписным сертификатом, и чтоб не ругалось, нужно это настроить - создать собственный локальный корневой сертификат и импортировать его в доверенные персональные хранилища системы и браузера (если такое нужно, то есть в самом низу этого ридми)

## Секреты специально хранятся в гите для упрощения тестового запуска.
- в наcтоящем проекте я бы использовал системы управления секретами: облачные сервисы типа AWS Secrets Manager, Azure Key Vault, Google Secret Manager, или сторонние решения типа HashiCorp Vault. И на сервер подтягивал бы через какой-нибудь ansible, загружал бы и генерировал .env файлы с секретами где нужно
- пример базовой настройки HashiCorp Vault реализовал для postgresql. Vault-agent загружает секреты для бд из Vault хранилища секретов. Используется базовый способ аутентификации через токен. В продакшене лучше использовать approle или другие более безопасные методы.

## Сервисы:
### Redis:

- используем как кеш для активных матчей, онлайн-статусов игроков и прочего;
- используем как Pub/Sub шину для синхронизации обмена сообщениями между клиентами websokets для нескольких инстансов сервера;

При работе с WebSocket важен постоянный двунаправленный канал между сервером и клиентом. При горизонтальном масштабировании (несколько экземпляров сервера, запущенных за балансировщиком нагрузки) клиент может подключиться к любому серверу. Когда нужно отправить сообщение клиенту, сервер должен доставить это сообщение вне зависимости от того, к какому именно из экземпляров клиент подключен.

Если серверы не связаны между собой, то пользователь, подключенный к серверу А, не получит сообщения, отправленные сервером Б. Решается это через общую систему обмена сообщениями (очередь, шина Pub/Sub).

Redis выступает как центральный Pub/Sub-брокер:

Каждый экземпляр сервера WebSocket подписывается на канал Redis для получения сообщений, предназначенных его подключенным клиентам.

Когда сервер А хочет отправить сообщение клиенту, который подключен к серверу Б, это сообщение публикуется в канал Redis.

Сервер Б получает это сообщение из Redis через подписку и пересылает клиенту по WebSocket.

Таким образом достигается синхронизация сообщений между всеми инстансами серверов.

Клиенты подключаются к балансировщику нагрузки (nginx), а backend работает с Redis для обмена сообщениями между инстансами.


### Postgres:

- храним данные о юзерах, проведенных матчах и прочем, что нужно хранить в долгую;


### PgAdmin:

- использую для управления и администрирования базы данных PostgreSQL
- vault-agent загружает секреты для бд из Vault хранилища секретов


### HashiCorp Vault

- использую для безопасного централизованного управления секретами и конфиденциальными данными

### Nginx:

- использую для проксирования WebSocket соединений от клиентов к нескольким инстансам NestJS сервера. Nginx устанавливает туннель WebSocket, обрабатывая заголовки Upgrade и Connection, чтобы корректно перенаправлять ws/wss-трафик. Это позволяет иметь единую точку входа для вебсокетов под одним доменом и портом, а не напрямую подключаться к backend-серверам

- балансировка нагрузки и маршрутизация запросов между тремя инстансами серверов, чтобы распределить трафик взаимодействия с гусем и нажатием на него. Nginx может направлять обычные HTTP-запросы (например, к REST API) и WebSocket-сообщения на разные сервера по upstream

- безопасность и поддержка HTTPS / WSS через SSL-сертификаты. Nginx терминирует SSL и предоставляет защищенный канал для клиента, особенно если в игре WebSocket используется защищенный протокол wss

- управление таймаутами, поддержка переоткрытия WebSocket при ошибках и разгрузка backend от прямой работы с соединениями клиентов, улучшая масштабируемость и отказоустойчивость игры с синхронизацией игроков через Redis Pub/Sub


### docker и docker compose:
- для создания и управления изолированными контейнерами для всех компонентов проекта: backend-серверов NestJS, базы данных PostgreSQL, кешей Redis, frontend-приложения на Vite/React и т.д
- для прощения запуска множества связанных сервисов с помощью файлов docker-compose.yml, где описываются все контейнеры, их настройки, сети и тома

### Сервер на NestJS:
- три инстанса сервера на NestJS;
- websoket.io для обеспечения двунаправленной, реального времени, низко-задержечной коммуникации между клиентами и сервером и redis шина Pub/Sub для синхронизации обмена сообщениями между клиентами websokets для нескольких инстансов сервера;
- валидация данных DTO с помощью class-validator и class-transformer;
- авторизация через jwt-токены и passport (рефреш-токены для данного примера не стал настраивать);
- пароли в бд шифруются с солью;
- настроено восстановление состояний матчей и websoket-подписок пользователей на комнаты матчей, в которых пользователи участвуют;
- создан сид для первичного заполнения БД тестовыми аккаунтами;
- настроен Swagger для автоматической генерации документации API;
- настроен nestjs-asyncapi для автоматической генерации документации AsyncAPI, которая описывает события и сообщения в асинхронной архитектуре, основанной на WebSocket и Redis Pub/Sub;
- prisma как ORM (Object-Relational Mapping) инструмент для удобного и типобезопасного взаимодействия с базой данных PostgreSQL;
- Helmet для повышения безопасности Node.js (NestJS) сервера через установку важных HTTP-заголовков, которые помогают защитить приложение от различных веб-уязвимостей, Helmet выступает как middleware;
- в архитектуру заложена возможность быстрого масштабирования и расширения количества игр (а не только одна игра);



### Frontend на React
- Vite как современный инструмент сборки и дев-сервер для фронтенда на React и TypeScript;
- Zustand для локального стейта и Tanstack Query для запросов на бекенд;
- Tailwind CSS как утилитарный CSS-фреймворк для быстрого, удобного и гибкого создания пользовательского интерфейса фронтенда на React;
- Axios как удобную JavaScript-библиотеку для выполнения HTTP-запросов с фронтенда (React)
- Pixi.js как мощный и быстрый 2D-рендеринг движок для создания интерактивной графики и анимаций в браузере
- Prettier для автоматического форматирования исходного кода вашего проекта;
- ESLint для статического анализа кода JavaScript и TypeScript с целью повышения качества и поддерживаемости проекта;
- WebSocket.io для двунаправленного постоянного соединения с сервером

## CI/CD:
Для начала, разнес бы все сервисы в отдельные репозитории. После для каждого настроил бы свой CI/CD по выкатке на тестовые и продовые сервера. Если ресурсы позволяют, то настроил бы следующим образом:

1. Сборка фронтенда (Vite React)
- Запускаются юнит-тесты, E2E тесты.
- Сборка production-артефакта (статичные файлы).
- Загрузка артефакта в объектное хранилище (например, S3, MinIO) или напрямую в Docker-образ.
- Вариант: хранить статику в CDN (Cloudflare, AWS CloudFront).

2. Сборка бекенда (NestJS)
- Запуск юнит- и интеграционных тестов.
- Построение Docker-образа с tagged git hash или версией.
- Складывание образа в Docker Registry (Docker Hub, GitHub Container Registry, Harbor).

3. Управление секретами и переменными окружения
- Использование HashiCorp Vault в пайплайне для подхвата секретов на каждом этапе (напр. подключение к базе, API ключи).
- Автоматическая подстановка секретов через Vault Agent или интеграция в Kubernetes Secrets (если есть Kubernetes).

4. Деплой контейнеров и сервисов
- Использование Docker Swarm, Kubernetes или orchestration с Ansible/Helm.
- Несколько инстансов NestJS для горизонтального масштабирования.
- Load balancing запросов через Nginx.
- Включение pgAdmin как отдельного защищенного сервиса.
- PostgreSQL и Redis с постоянным хранилищем (volume), регулярные бэкапы.
- Непрерывный деплой с Canary deploy / Blue-Green deploy:
- Для фронтенда с версионированием статики и быстрого отката (автоматический rollback).
- Для бекенда с поэтапным переключением трафика и мониторингом ошибок.
- Мониторинг: Prometheus + Grafana + Loki для логов, алерты на сбои.

Конкретно для фронта мог бы рассмотреть несколько решений в зависимости от требований и имеющихся ресурсов:
- GitHub Actions + Docker Hub. Скрипт в GitHub Actions, сборка и пуш образа, деплой на сервер по SSH/Docker Compose. Плюсы: Простота, хорошая интеграция с репозиторием. Минусы: Не самый продвинутый orchestration, ручные этапы.
- GitLab CI + Kubernetes. Полный пайплайн с Helm-чартами и интеграцией Vault через Kubernetes Secrets. Плюсы: Высокая автоматизация, масштабируемость. Минусы: Сложность настройки и поддержки Kubernetes.
- Jenkins (или даже лучше Teamcity) + Ansible. Jenkins (Teamcity) для pipeline, Ansible для деплоя на кластер, Vault для секретов. Плюсы: Гибкость, кастомизация. Минусы: Требует поддержки инфраструктуры.

## Полезные команды

### START ALL CONTAINERS:
```
./start-dev-all.sh
or
./start-prod-all.sh
```

### STOP ALL CONTAINERS:
```
./stop-dev-all.sh
or
./stop-prod-all.sh
```
### Применить изменения в nginx.conf:
`docker compose -f docker-compose.dev.yaml exec nginx sh`
`nginx -s reload`

### Prisma
`yarn prisma migrate dev --name init`
`yarn prisma:seed`
`yarn prisma:seed-undo`
`yarn prisma db push`
`yarn prisma generate`


### Подробнее об установке локального сертификата в Ubuntu 24, чтоб не ругалось:

- Установите необходимые пакеты:
```
sudo apt update
sudo apt install libnss3-tools wget curl
```

- Скачайте бинарник mkcert для Linux amd64:
```
curl -JLO "https://dl.filippo.io/mkcert/latest?for=linux/amd64"
```

- Сделайте бинарник исполняемым и переместите в /usr/local/bin:
```
chmod +x mkcert-v*-linux-amd64
sudo mv mkcert-v*-linux-amd64 /usr/local/bin/mkcert
```

- Проверьте установку:
```
mkcert --versionmkcert --version
```

- Создайте сертификат для localhost (выполните в каталоге вашего проекта или отдельной папке):
```
mkcert localhost
```

- перейдите в дирректорию с сертификатами:
```
cd ./nginx/files/certs/
```

- Создайте сертификат для localhost (выполните в каталоге вашего проекта или отдельной папке):
```
mkcert localhost
```

- После этого в текущей директории появятся два файла: localhost.pem (сертификат) и localhost-key.pem (закрытый ключ).

- Перезапустите nginx и зайдите в https://localhost — соединение признано безопасным без ошибок браузера.

